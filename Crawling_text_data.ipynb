{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-e3ba7Phg-3",
        "outputId": "8027b2ac-40c1-43fe-bcb4-8f52c44cd99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.21.0 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "r4LMGG-qhllm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a browser\n",
        "service = Service()\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--headless=new\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "driver = webdriver.Chrome(service=service, options=options)"
      ],
      "metadata": {
        "id": "f-sZhurth40K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dir\n",
        "root_dir = './corpus'\n",
        "os.makedirs(root_dir, exist_ok=True)\n",
        "list_of_topics = [\"data-speaks\", \"property\", \"markets\", \"companies\", \"economy\", \"exchange-rate\", \"money\"]\n",
        "article_id = 0\n",
        "img_id = 0"
      ],
      "metadata": {
        "id": "S757bFBLiTen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of URLs\n",
        "for topic in tqdm(list_of_topics):\n",
        "  main_url = f\"https://e.vnexpress.net/news/business/{topic}\"\n",
        "  driver.get(main_url)\n",
        "  time.sleep(1)\n",
        "\n",
        "  tags_xpath = '//*[@id=\"vnexpress_folder_list_news\"]/div/div[1]/div[1]/a'\n",
        "\n",
        "  list_of_tags = driver.find_elements(\n",
        "      By.XPATH, tags_xpath\n",
        "  )\n",
        "  list_of_urls = [tag.get_attribute(\"href\") for tag in list_of_tags]\n",
        "\n",
        "  for url in list_of_urls:\n",
        "    # Access to url\n",
        "    try:\n",
        "      driver.get(url)\n",
        "      time.sleep(1)\n",
        "    except:\n",
        "      raise Exception(f\"Cannot access to {url}\")\n",
        "\n",
        "    # Get title\n",
        "    title_xpath = '//*[@id=\"detail_page\"]/div[1]/div[2]/div/div[2]/div[1]/div/div/h1'\n",
        "    try:\n",
        "      title = driver.find_element(\n",
        "          By.XPATH, title_xpath\n",
        "      ).text.strip()\n",
        "    except:\n",
        "      raise Exception(f\"Cannot get title of {url}\")\n",
        "\n",
        "    #  Get author\n",
        "    author_xpath = '//*[@id=\"detail_page\"]/div[1]/div[2]/div/div[2]/div[2]/a'\n",
        "    try:\n",
        "      author = driver.find_element(\n",
        "          By.XPATH, author_xpath\n",
        "      ).text.strip()\n",
        "    except:\n",
        "      author = '' # cannot set author to None bc of join() method at the end of te code\n",
        "\n",
        "    # Get thumbnail\n",
        "    img_xpath = '//*[@id=\"detail_page\"]/div[1]/div[2]/div/div[2]/div[3]/img'\n",
        "    try:\n",
        "      img_tags = driver.find_elements(\n",
        "          By.XPATH, img_xpath\n",
        "      )\n",
        "    except:\n",
        "      raise Exception(f\"Cannot get img tags of {url}\")\n",
        "    else:\n",
        "      img_urls = [img_tag.get_attribute('src') for img_tag in img_tags]\n",
        "      if img_urls is None:\n",
        "        img_id += 1\n",
        "      else:\n",
        "        for img_url in img_urls:\n",
        "          img_url_res = requests.get(img_url)\n",
        "          try:\n",
        "            img = Image.open(BytesIO(img_url_res.content))\n",
        "          except:\n",
        "            raise Exception(f\"Cannot open thumbnail of {url}\")\n",
        "          if img.mode == \"P\":\n",
        "            img = img.convert(\"RBG\")\n",
        "          # Save img to .png file\n",
        "          img_name = f\"img_{img_id:05d}.png\"\n",
        "          img_save_path = os.path.join(\n",
        "              root_dir, img_name\n",
        "          )\n",
        "          img.save(img_save_path)\n",
        "          img_id += 1\n",
        "\n",
        "    # Get abstract\n",
        "    abstract_xpath = '//*[@id=\"detail_page\"]/div[1]/div[2]/div/div[2]/span'\n",
        "    try:\n",
        "      abstract = driver.find_element(\n",
        "          By.XPATH, abstract_xpath\n",
        "      ).text.strip()\n",
        "    except:\n",
        "      raise Exception(f\"Cannot get abstract of {url}\")\n",
        "\n",
        "    # Get paragraph\n",
        "    paragraph_tags_xpath = '//*[@id=\"detail_page\"]/div[1]/div[2]/div/div[2]/div[4]'\n",
        "    try:\n",
        "      paragraph_tags = driver.find_elements(\n",
        "          By.XPATH, paragraph_tags_xpath\n",
        "      )\n",
        "    except:\n",
        "      raise Exception(f\"Cannot get paragraphs of {url}\")\n",
        "    paragraphs = ' '.join([paragraph_tag.text.strip() for paragraph_tag in paragraph_tags])\n",
        "    content = '\\n\\n'.join([title, author, abstract, paragraphs])\n",
        "    # Save content to file\n",
        "    article_name = f\"article_{topic}_{article_id:05d}\"\n",
        "    article_save_path = os.path.join(\n",
        "        root_dir, article_name\n",
        "    )\n",
        "    article_id += 1\n",
        "    with open(article_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "      f.write(content)"
      ],
      "metadata": {
        "id": "TehLdVwan_Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebb6b56-2415-468a-a12f-63850a9f2a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [05:20<00:00, 45.76s/it]\n"
          ]
        }
      ]
    }
  ]
}